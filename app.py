import streamlit as st
from PIL import Image
import requests
from io import BytesIO
import base64
import os
import json
from datetime import datetime
import pandas as pd
import torch
from transformers import CLIPProcessor, CLIPModel
from sklearn.metrics.pairwise import cosine_similarity
import csv
import random

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

# å®šæ•°ã®è¨­å®š
POSTS_FILE = "data/posts.json"
PRODUCT_INFO_CSV = "data/product_info.csv"
GENERATED_IMAGE_PATH = "data/generated.png"
BASE_IMAGE_URL = "https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/sample_clothes/sample_images"

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
os.makedirs("data", exist_ok=True)
if not os.path.exists(POSTS_FILE):
    with open(POSTS_FILE, "w") as f:
        json.dump([], f)

# ãƒ€ãƒŸãƒ¼å•†å“ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
def generate_dummy_product_info():
    filenames = [f"100{n:02}.jpg" for n in range(20, 40)]
    with open(PRODUCT_INFO_CSV, "w") as f:
        writer = csv.writer(f)
        writer.writerow(["filename", "name", "price", "stock"])
        for fname in filenames:
            name = f"ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ  {fname.split('.')[0]}"
            price = f"Â¥{random.randint(3000, 8000)}"
            stock = random.choice(["åœ¨åº«ã‚ã‚Š", "åœ¨åº«å°‘", "å£²åˆ‡ã‚Œ"])
            writer.writerow([fname, name, price, stock])

if not os.path.exists(PRODUCT_INFO_CSV):
    generate_dummy_product_info()

# CLIPãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# ç”»åƒã®ãƒ™ã‚¯ãƒˆãƒ«å–å¾—
def get_image_embedding_from_url(img_url):
    image = Image.open(requests.get(img_url, stream=True).raw).convert("RGB")
    inputs = clip_processor(images=image, return_tensors="pt")
    with torch.no_grad():
        features = clip_model.get_image_features(**inputs)
    return features / features.norm()

def get_image_embedding(image_path):
    image = Image.open(image_path).convert("RGB")
    inputs = clip_processor(images=image, return_tensors="pt")
    with torch.no_grad():
        features = clip_model.get_image_features(**inputs)
    return features / features.norm()

# é¡ä¼¼å•†å“TOP3ã®å–å¾—
def find_top_similar_products_from_url(coord_path, top_k=3):
    coord_vec = get_image_embedding(coord_path)
    df = pd.read_csv(PRODUCT_INFO_CSV)
    sims = []
    for _, row in df.iterrows():
        img_url = f"{BASE_IMAGE_URL}/{row['filename']}"
        try:
            product_vec = get_image_embedding_from_url(img_url)
            sim = cosine_similarity(coord_vec, product_vec)[0][0]
            sims.append((row, sim))
        except Exception as e:
            continue
    top = sorted(sims, key=lambda x: x[1], reverse=True)[:top_k]
    return [(f"{BASE_IMAGE_URL}/{r[0]['filename']}", r[0]) for r in top]

# æŠ•ç¨¿ã®èª­ã¿è¾¼ã¿ã¨ä¿å­˜
def load_posts():
    with open(POSTS_FILE, "r") as f:
        return json.load(f)

def save_post(post):
    posts = load_posts()
    posts.append(post)
    with open(POSTS_FILE, "w") as f:
        json.dump(posts, f)

# Streamlitã®è¨­å®š
st.set_page_config(page_title="RetailNext Portal", layout="wide")
st.title("ğŸŒŸ RetailNext Coordinator")

tab1, tab2, tab3 = st.tabs(["ğŸ§  ã‚³ãƒ¼ãƒ‡è¨ºæ–­", "ğŸŒ ã¿ã‚“ãªã®ã‚³ãƒ¼ãƒ‡", "ğŸ”¥ äººæ°—ãƒ©ãƒ³ã‚­ãƒ³ã‚°"])

# ã‚¿ãƒ–1ï¼šã‚³ãƒ¼ãƒ‡ç”Ÿæˆ
with tab1:
    with st.form("form"):
        uploaded_image = st.file_uploader("ğŸ“¸ è‡ªåˆ†ã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "jpeg"])
        country = st.text_input("ğŸŒ å›½")
        gender = st.selectbox("æ€§åˆ¥", ["ç”·æ€§", "å¥³æ€§", "ãã®ä»–"])
        age = st.slider("å¹´é½¢", 1, 100, 25)
        body = st.selectbox("ä½“å‹", ["ã‚¹ãƒªãƒ ", "æ¨™æº–", "ã½ã£ã¡ã‚ƒã‚Š"])
        color = st.color_picker("ğŸ¨ å¥½ããªè‰²")
        style = st.selectbox("ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«", ["æ—¥æœ¬", "ãƒ‡ã‚£ã‚ºãƒ‹ãƒ¼", "ã‚¢ãƒ¡ã‚³ãƒŸ", "CG"])
        theme = st.text_input("ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒï¼ˆä¾‹ï¼šæ˜¥ã£ã½ãï¼‰")
        submitted = st.form_submit_button("âœ¨ AIã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆç”Ÿæˆ")

    if submitted:
        if uploaded_image is None:
            st.warning("ğŸ“· ã¾ãšã¯è‡ªåˆ†ã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        else:
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            prompt = f"""
ä»¥ä¸‹ã®ãŠå®¢æ§˜ã®è¦æœ›ã«åˆã†ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆç”»åƒã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»å›½: {country} / æ€§åˆ¥: {gender} / å¹´é½¢: {age} / ä½“å‹: {body}
ãƒ»å¥½ããªè‰²: {color} / ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ: {theme} / ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«: {style}
èƒŒæ™¯ã¯ç™½ã€å…¨èº«ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã®äººç‰©1äººã ã‘ã«ã—ã¦ãã ã•ã„ã€‚
"""
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024",
                quality="standard",
                n=1
            )
            image_url = response.data[0].url
            st.image(image_url, caption="ğŸ§  AIã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆ", use_column_width=True)

            img = Image.open(requests.get(image_url, stream=True).raw).convert("RGB")
            img.save(GENERATED_IMAGE_PATH)

            st.subheader("ğŸ› é¡ä¼¼å•†å“ï¼ˆAIæ¨è–¦ï¼‰")
            top_items = find_top_similar_products_from_url(GENERATED_IMAGE_PATH)
            cols = st.columns(3)
            for col, (img_url, item) in zip(cols, top_items):
                with col:
                    st.image(img_url, use_column_width=True)
                    st.caption(f"{item['name']} / {item['price']} / {item['stock']}")
                    st.markdown("[ğŸ›’ ã‚«ãƒ¼ãƒˆã«è¿½åŠ ](#)")

            if st.button("ğŸŒ ã‚³ãƒ¼ãƒ‡ã‚’å…±æœ‰ã™ã‚‹"):
                save_post({
                    "timestamp": str(datetime.now()),
                    "image_url": image_url,
                    "country": country,
                    "gender": gender,
                    "age": age,
                    "body":
::contentReference[oaicite:2]{index=2}
 
